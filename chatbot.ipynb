{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import api_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_nzNSD9B6lK9Gf9gzFTvjW9LP', 'function': {'arguments': '{\"character_name\":\"지우\",\"universe\":\"포켓몬스터\",\"requirements\":\"없음\",\"user_name\":\"여행자\"}', 'name': 'Profile'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 208, 'total_tokens': 244, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BJbxJw76hsHrlTv1k4d9th8loKTTh', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6715f1a4-1ce2-4bb5-bc45-fc6948047339-0', tool_calls=[{'name': 'Profile', 'args': {'character_name': '지우', 'universe': '포켓몬스터', 'requirements': '없음', 'user_name': '여행자'}, 'id': 'call_nzNSD9B6lK9Gf9gzFTvjW9LP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 208, 'output_tokens': 36, 'total_tokens': 244, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "class Profile(BaseModel):\n",
    "    character_name: str\n",
    "    universe: str\n",
    "    requirements: str\n",
    "    user_name: str\n",
    "\n",
    "profile_system_prompt = '''Your role is to become a character who engages in conversation with the user.\n",
    "To do this, you should collect the following information from the user:\n",
    "\n",
    "- What the character's name is\n",
    "- What universe(세계관, 영화, 게임 등) does the character belong to\n",
    "- What the user's requirements are\n",
    "- Whtr the user's name is\n",
    "\n",
    "If you cannot determine this information, ask the user directly to clarify — preferably using a bullet-point or structured format. Do not make assumptions.\n",
    "Once you have all the necessary information, confirm it with the user one more time, and then call the relevant tool.'''\n",
    "\n",
    "\n",
    "llm  = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "profiling_llm = llm.bind_tools([Profile])\n",
    "\n",
    "profiling_llm.invoke([(\"assistant\", profile_system_prompt),(\"user\", \"character name:지우, universe: 포켓몬스터, requirements: 없음, my name is 여행자. 정보 확인완료. 바로 시작하자\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 검색 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '[Capstone #1] RAG : Retrieval-Augmented Generation - velog',\n",
       "  'url': 'https://velog.io/@yun_haaaa/RAG-Retrieval-Augmented-Generation',\n",
       "  'content': 'RAG란? RAG는 기존 모델 외부에서 관련 데이터를 검색하여 입력을 향상시키는 방법으로, 이를 통해 결과를 개선하며 더 풍부한 맥락을',\n",
       "  'score': 0.89324445},\n",
       " {'title': '검색 증강 생성(RAG)이란? | 포괄적인 RAG 안내서 - Elastic',\n",
       "  'url': 'https://www.elastic.co/kr/what-is/retrieval-augmented-generation',\n",
       "  'content': 'RAG(검색 증강 생성)란 무엇인가?\\nRAG 기본 요소를 넘어서\\n검색 증강 생성(RAG)의 정의\\n검색 증강 생성(RAG)은 프라이빗 또는 독점 데이터 소스의 정보로 텍스트 생성을 보완하는 기술입니다. 대규모 데이터 세트 또는 지식 기반을 검색하도록 설계된 검색 모델에 해당 정보를 가져와 읽을 수 있는 텍스트 응답을 생성하는 대규모 언어 모델(LLM)과 같은 생성 모델을 결합합니다.\\n검색 증강 생성은 추가 데이터 소스의 컨텍스트를 더하고 훈련을 통해 LLM의 원래 지식 기반을 보완함으로써 검색 경험의 정확도를 개선할 수 있습니다. 따라서 모델을 다시 훈련할 필요 없이 대규모 언어 모델의 출력이 향상됩니다. 추가 정보 소스는 LLM의 훈련에 사용되지 않은 인터넷의 새로운 정보부터 독점 비즈니스 컨텍스트 또는 비즈니스에 속한 기밀 내부 문서에 이르기까지 다양합니다. [...] RAG는 생성형 AI 시스템이 외부 정보 소스를 사용하여 보다 정확한 상황 인식 응답을 생성할 수 있도록 해주기 때문에 질문 답변 및 콘텐츠 생성과 같은 작업에 유용합니다. 일반적으로 시맨틱 검색이나 하이브리드 검색과 같은 검색 방법을 구현하여 사용자 의도에 응답하고 보다 정확한 결과를 제공합니다.\\n검색 증강 생성(RAG)과 이 접근 방식을 통해 독점적인 실시간 데이터를 생성형 AI 모델에 연결하여 최종 사용자 경험과 정확성을 개선하는 방법에 대해 자세히 알아보세요.\\n정보 검색이란?\\n정보 검색(IR)이란 지식 소스나 데이터 세트에서 관련 정보를 검색하고 추출하는 프로세스를 말합니다. 이는 검색 엔진을 사용하여 인터넷에서 정보를 찾는 것과 매우 유사합니다. 사용자가 쿼리를 입력하면 시스템은 사용자가 찾고 있는 정보를 포함할 가능성이 가장 높은 문서나 웹 페이지를 검색하여 표시합니다. [...] RAG는 외부 참조를 정기적으로 업데이트할 수 있으므로 모델이 가장 최근의 사실 및 관련 정보에 액세스할 수 있는지 확인합니다. 이렇게 하면 RAG가 생성하는 응답에는 쿼리를 수행하는 사용자와 관련이 있을 수 있는 최신 정보가 포함됩니다. 또한 문서 수준 보안을 구현하여 데이터 스트림 내의 데이터에 대한 액세스를 제어하고 특정 문서에 대한 보안 권한을 제한할 수 있습니다.\\nRAG는 필요한 컴퓨팅과 저장 공간이 더 적으므로 보다 비용 효율적인 옵션입니다. 즉, 자체 LLM을 보유할 필요가 없고 모델을 미세 조정하는 데 시간과 비용을 들일 필요가 없습니다.\\n정확성을 주장하는 것과 이를 실제로 증명하는 것은 별개의 문제입니다. RAG는 외부 소스를 인용하고 이를 사용자에게 제공하여 응답을 뒷받침할 수 있습니다. 원하는 경우 사용자는 소스를 평가하여 받은 응답이 정확한지 확인할 수 있습니다.',\n",
       "  'score': 0.88705814},\n",
       " {'title': '검색 증강 생성(RAG)이란 무엇인가요? - AI - AWS',\n",
       "  'url': 'https://aws.amazon.com/ko/what-is/retrieval-augmented-generation/',\n",
       "  'content': 'RAG(Retrieval-Augmented Generation)는 대규모 언어 모델의 출력을 최적화하여 응답을 생성하기 전에 학습 데이터 소스 외부의 신뢰할 수 있는 지식 베이스를 참조하도록 하는 프로세스입니다. 대규모 언어 모델(LLM)은 방대한 양의 데이터를 기반으로 학습되며 수십억 개의 매개 변수를 사용하여 질문에 대한 답변, 언어 번역, 문장 완성과 같은 작업에 대한 독창적인 결과를 생성합니다. RAG는 이미 강력한 LLM의 기능을 특정 도메인이나 조직의 내부 지식 기반으로 확장하므로 모델을 다시 교육할 필요가 없습니다. 이는 LLM 결과를 개선하여 다양한 상황에서 관련성, 정확성 및 유용성을 유지하기 위한 비용 효율적인 접근 방식입니다.\\n검색-증강 생성이 중요한 이유는 무엇인가요? [...] 대형 언어 모델은 현재 상황에 대한 최신 정보를 얻기를 거부하지만 항상 절대적인 자신감을 가지고 모든 질문에 답변하는 지나치게 열정적인 신입 사원으로 생각할 수 있습니다. 안타깝게도 이러한 태도는 사용자 신뢰에 부정적인 영향을 미칠 수 있으며 챗봇이 모방하기를 원하지 않습니다!\\nRAG는 이러한 문제 중 일부를 해결하기 위한 한 가지 접근 방식입니다. LLM을 리디렉션하여 신뢰할 수 있는 사전 결정된 지식 출처에서 관련 정보를 검색합니다. 조직은 생성된 텍스트 출력을 더 잘 제어할 수 있으며 사용자는 LLM이 응답을 생성하는 방식에 대한 통찰력을 얻을 수 있습니다.\\n검색-증강 생성의 이점은 무엇인가요?\\nRAG 기술은 조직의 생성형 AI 노력에 여러 가지 이점을 제공합니다.\\n비용 효율적인 구현 [...] 챗봇 개발은 일반적으로 파운데이션 모델을 사용하여 시작됩니다. 파운데이션 모델(FM)은 광범위한 일반화 데이터와 레이블이 지정되지 않은 데이터에 대해 훈련된 API 액세스 가능 LLM입니다. 조직 또는 도메인별 정보를 위해 FM을 재교육하는 데 드는 계산 및 재정적 비용이 많이 듭니다. RAG는 LLM에 새 데이터를 도입하기 위한 보다 비용 효율적인 접근 방식입니다. 이를 통해 생성형 인공 지능(생성형 AI) 기술을 보다 폭넓게 접근하고 사용할 수 있습니다.\\n최신 정보\\nLLM의 원본 훈련 데이터 소스가 요구 사항에 적합하더라도 관련성을 유지하기는 어렵습니다. 개발자는 RAG를 사용하여 생성 모델에 최신 연구, 통계 또는 뉴스를 제공할 수 있습니다. RAG를 사용하여 LLM을 라이브 소셜 미디어 피드, 뉴스 사이트 또는 기타 자주 업데이트되는 정보 소스에 직접 연결할 수 있습니다. 그러면 LLM은 사용자에게 최신 정보를 제공할 수 있습니다.\\n사용자 신뢰 강화',\n",
       "  'score': 0.8745175},\n",
       " {'title': 'RAG (검색증강생성)이란? - 글래스 비드 게임 - 티스토리',\n",
       "  'url': 'https://futures-studies.tistory.com/entry/RAG-%EA%B2%80%EC%83%89%EC%A6%9D%EA%B0%95%EC%83%9D%EC%84%B1%EC%9D%B4%EB%9E%80',\n",
       "  'content': 'RAG는 Retrieval-Augmented Generation의 약자로 우리말로는 검색증강생성이라고 합니다. 정보 검색(IR)과 자연어 생성(NLG) 모델을 결합하여 AI가 더',\n",
       "  'score': 0.86303437},\n",
       " {'title': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향',\n",
       "  'url': 'https://www.skelterlabs.com/blog/2024-year-of-the-rag',\n",
       "  'content': '2023년은 ChatGPT, Llama-2와 같은 기초적인 대형 언어 모델(LLM)들에 관한 해였다면, 2024년은 RAG (Retrieval Augmented Generation; 검색 증강 생성) 와 AI Agent(AI 에이전트)의 해가 될 것이라고 다수의 필드 전문가들은 예측합니다.\\n이번 블로그 포스트에서는 2024년에 RAG가 주목 받는 이유, 작동 방식, 그리고 파인튜닝 방식과의 비교 등 RAG의 기초 상식을 살펴보도록 하겠습니다.\\n📖 목차\\n• RAG 란?\\n• RAG가 주목 받는 이유\\n• RAG의 장점 3가지\\n• RAG 작동 방식\\n• RAG vs. Fine-tuning(파인튜닝)\\n• RAG의 미래 동향\\n\\u200d\\n📍RAG란?\\nRetrieval-augmented generation(RAG; 검색증강생성)은 외부 지식 베이스에서 사실을 검색하여 대형 언어 모델(LLM)을 가장 정확하고 최신의 정보에 근거하는 AI 프레임워크입니다.',\n",
       "  'score': 0.85421735}]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "web_search_tool.invoke({\"query\": \"RAG란?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info 검색 쿼리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_search_system_prompt = \"\"\"Your role is to investigate character information based on the details provided by the user.\n",
    "Given a character's name and universe, generate the most effective and natural web search query to gather information about the character's background, personality, and Character's says.\n",
    "\n",
    "You MUST output the search query only.\"\"\"\n",
    "\n",
    "info_web_search_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", info_search_system_prompt),\n",
    "        (\"user\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "info_web_search_chain = info_web_search_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"지우 포켓몬스터 캐릭터 배경 성격 대사\"\n"
     ]
    }
   ],
   "source": [
    "web_query = info_web_search_chain.invoke({\"question\": {\"name\": \"지우\", \"universe\": \"포켓몬스터\", \"requirements\": \"없음\"}})\n",
    "print(web_query)\n",
    "web_search_tool.invoke(web_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector DB 및 Retriever 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='2023년은 ChatGPT, Llama-2와 같은 기초적인 대형 언어 모델(LLM)들에 관한 해였다면, 2024년은 RAG (Retrieval Augmented Generation; 검색 증강 생성) 와 AI Agent(AI 에이전트)의 해가 될 것이라고 다수의 필드 전문가들은 예측합니다.\\n이번 블로그 포스트에서는 2024년에 RAG가 주목 받는 이유, 작동 방식, 그리고 파인튜닝 방식과의 비교 등 RAG의 기초 상식을 살펴보도록 하겠습니다.\\n📖 목차\\n• RAG 란?\\n• RAG가 주목 받는 이유\\n• RAG의 장점 3가지\\n• RAG 작동 방식\\n• RAG vs. Fine-tuning(파인튜닝)\\n• RAG의 미래 동향\\n\\u200d\\n📍RAG란?'),\n",
       " Document(metadata={}, page_content='2023년은 ChatGPT, Llama-2와 같은 기초적인 대형 언어 모델(LLM)들에 관한 해였다면, 2024년은 RAG (Retrieval Augmented Generation; 검색 증강 생성) 와 AI Agent(AI 에이전트)의 해가 될 것이라고 다수의 필드 전문가들은 예측합니다.\\n이번 블로그 포스트에서는 2024년에 RAG가 주목 받는 이유, 작동 방식, 그리고 파인튜닝 방식과의 비교 등 RAG의 기초 상식을 살펴보도록 하겠습니다.\\n📖 목차\\n• RAG 란?\\n• RAG가 주목 받는 이유\\n• RAG의 장점 3가지\\n• RAG 작동 방식\\n• RAG vs. Fine-tuning(파인튜닝)\\n• RAG의 미래 동향\\n\\u200d\\n📍RAG란?'),\n",
       " Document(metadata={}, page_content='RAG(Retrieval-Augmented Generation)는 대규모 언어 모델의 출력을 최적화하여 응답을 생성하기 전에 학습 데이터 소스 외부의 신뢰할 수 있는 지식 베이스를 참조하도록 하는 프로세스입니다. 대규모 언어 모델(LLM)은 방대한 양의 데이터를 기반으로 학습되며 수십억 개의 매개 변수를 사용하여 질문에 대한 답변, 언어 번역, 문장 완성과 같은 작업에 대한 독창적인 결과를 생성합니다. RAG는 이미 강력한 LLM의 기능을 특정 도메인이나 조직의 내부 지식 기반으로 확장하므로 모델을 다시 교육할 필요가 없습니다. 이는 LLM 결과를 개선하여 다양한 상황에서'),\n",
       " Document(metadata={}, page_content='RAG(Retrieval-Augmented Generation)는 대규모 언어 모델의 출력을 최적화하여 응답을 생성하기 전에 학습 데이터 소스 외부의 신뢰할 수 있는 지식 베이스를 참조하도록 하는 프로세스입니다. 대규모 언어 모델(LLM)은 방대한 양의 데이터를 기반으로 학습되며 수십억 개의 매개 변수를 사용하여 질문에 대한 답변, 언어 번역, 문장 완성과 같은 작업에 대한 독창적인 결과를 생성합니다. RAG는 이미 강력한 LLM의 기능을 특정 도메인이나 조직의 내부 지식 기반으로 확장하므로 모델을 다시 교육할 필요가 없습니다. 이는 LLM 결과를 개선하여 다양한 상황에서')]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = web_search_tool.invoke({\"query\": \"RAG란?\"})\n",
    "\n",
    "embd = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding_function=embd\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "docs = [Document(page_content=result[\"content\"]) for result in search_result]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=600, chunk_overlap=100\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore.add_documents(doc_splits)\n",
    "\n",
    "retriever.invoke(\"RAG에서 학습이 진행되나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval 평가 Chain 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision='yes'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class EvalDocuments(BaseModel):\n",
    "    \"\"\"\n",
    "    Document evaluation class.\n",
    "    The decision attribute can have a value of 'yes' or 'no' indicating the relevance of the document to the message.\n",
    "    \"\"\"\n",
    "    decision: str = Field(description=\"Documents are relevant to message. This attribute can have a value of 'yes' or 'no'\")\n",
    "    \n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "retrieval_llm_evaluator = llm.with_structured_output(EvalDocuments)\n",
    "\n",
    "retrieval_eval_system = \"\"\"You are an evaluator responsible for assessing whether a retrieved document is relevant to the user's message.\n",
    "The user is having a conversation with a character. If the document contains related keywords or is semantically connected to the user's message, evaluate it as relevant.\n",
    "Your goal is to filter out incorrectly retrieved documents.\n",
    "If the user's message is related to the document, output 'yes'; otherwise, output 'no'.\"\"\"\n",
    "\n",
    "retrieval_eval_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", retrieval_eval_system),\n",
    "        (\"user\", \"Character Profile and User Name : {profile}\\n\\nRetrieved Document: {document}\\n\\nMessage: {message}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_evaluator = retrieval_eval_prompt | retrieval_llm_evaluator\n",
    "\n",
    "character_name = \"지우\"\n",
    "universe = \"포켓몬스터\"\n",
    "doc_text = \"지우의 파트너는 피카츄이다.\"\n",
    "message = \"너의 파트너는 피카츄야.\"\n",
    "\n",
    "print(retrieval_evaluator.invoke({\"character_name\":character_name, \"universe\":universe, \"document\":doc_text, \"message\":message}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요정보 웹 검색 쿼리 작성 chain 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_query_gen_system_prompt = \"\"\"You are role-playing with user and acting as a given character. To respond to the user's messages, you need to perform web searches.\n",
    "Your role is to generate an appropriate web search query to obtain the knowledge necessary to answer the user's messages.\n",
    "Output the web search query — do not output anything else.\"\"\"\n",
    "\n",
    "web_query_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", web_query_gen_system_prompt),\n",
    "        (\"user\", \"Character Profile and User Name : {profile}\\n\\n  User's Message: {message}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "web_search_chain = web_query_gen_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '피카츄 - 위키백과, 우리 모두의 백과사전',\n",
       "  'url': 'https://ko.wikipedia.org/wiki/%ED%94%BC%EC%B9%B4%EC%B8%84',\n",
       "  'content': \"한지우와 피카츄의 만남을 그리는 애니메이션의 제1화의 줄거리는 이와 같다. 주인공 한지우는 태초마을의 나어린 소년으로서 올해 10살이 되어 포켓몬을 가질 자격이 주어졌다. 포켓몬 마스터가 될 생각에 들떠 꿈속에서마저 몬스터볼을 던지는 꿈을 꾸었는데 그게 자명종을 망가뜨리는 짓이 되고 만다. 지우는 급히 오박사의 연구소로 달려갔지만 스타팅 포켓몬은 다 주어지고 없는 상태였다. 실망한 지우에게 오박사는 포켓몬이 한 마리 남아 있다고 알려줬는데 바로 수컷 피카츄였다. 다만 이 피카츄는 성격이 사나워서 지우의 말을 따르지 않고 툭하면 전기공격을 먹이며 포켓몬을 담아 편하게 옮길 수 있는 몬스터볼에도 갑갑하다면서 들어가지 않으려는 것이었다. 이렇게 생각이 서로 맞지 않던 둘이었지만, 깨비참 떼에 함께 쫓기고 깨비참의 몰매를 맞던 것을 지우가 몸을 던져 구해주고[45] 자신을 성의있게 대해주면서 피카츄도 마음을 돌리게 된다. 그리하여 서로의 마음속에는 우정이 싹텄지만, 여전히 피카츄는 [...] 피카츄(일본어: ピカチュウ 피카추[*][주 1] 문화어: 삐까쮸)는 《포켓몬스터》에 등장하는 가상의 생명체이다. 애니메이션과 비디오 게임에서는 오타니 이쿠에가 그 목소리를 맡고 있다. 귀여운 전기 포켓몬을 그려달라는 스기모리 켄의 주문을 받아 니시다 아츠코가 디자인하였다.[1] 게임 프리크와 닌텐도가 만든 1996년 일본 비디오 게임 《포켓몬스터 레드·그린》에 처음 등장했으며 1998년 《포켓몬스터 레드·블루》로 미국에 출시되었다. 피카츄는 전기 능력을 가진 노란색 쥐처럼 생긴 생물이다. 피카츄는 포켓몬 프랜차이즈의 주요 캐릭터이며, 마스코트이자 닌텐도의 주요 마스코트 역할을 한다. [...] 피카츄는 가장 인기 있고 잘 알려진 1세대 포켓몬인데, 포켓몬스터 TV 애니메이션에서 주인공 지우의 첫 포켓몬이자 파트너로 등장하기 때문이다. 1998년부터 지금까지 포켓몬스터의 애니메이션 주인공 지우와 함께 모험하고 있다. 피카츄는 대부분의 목소리 출연을 오타니 이쿠에가 담당했지만, 실사 애니메이션 영화 《명탐정 피카츄》에서 라이언 레이놀즈가 담당했다. 피카츄는 특히 귀여운 면모로 호평받으며 일본 대중문화의 아이콘으로 여겨지고 있다.\\n\\n만들어지기까지\\n\\n포켓몬 시리즈는 1996년 시작한 게임 프리크 개발·닌텐도 배급의 비디오 게임이다. 시리즈에는 '포켓몬'이라고 하는 가상의 생명체가 여럿 존재하여 플레이어, 즉 '트레이너'는 게임의 지침에 따라 포켓몬을 잡아 기르고 그렇게 기른 포켓몬으로 다른 트레이너의 포켓몬이나 야생의 포켓몬과 싸우게 된다.[2] 피카츄는 그러한 포켓몬의 한 종으로서 게임 프리크의 캐릭터 개발팀에서 구상한 것이다.\",\n",
       "  'score': 0.6641271},\n",
       " {'title': '태초마을에서 회색시티로! 포켓몬스터 레츠고 피카츄 #1 - YouTube',\n",
       "  'url': 'https://www.youtube.com/watch?v=dpuw1cbQVlg',\n",
       "  'content': '태초마을에서 회색시티로! 포켓몬스터 레츠고 피카츄 #1 · Comments1.',\n",
       "  'score': 0.5889134},\n",
       " {'title': '레츠고! 피카츄/이브이 스토리 공략 : 4. 세번째 체육관 - 네이버 블로그',\n",
       "  'url': 'https://m.blog.naver.com/riomedevon/221406682702',\n",
       "  'content': '<포켓몬스터 레츠고! 피카츄 - 여자 주인공>\\n\\n\\u200b\\n\\n<포켓몬스터 레츠고! 이브이 - 남자 주인공>\\u200b\\n\\n\\u200b\\n\\n태초마을에서 입수한 스포츠웨어가 피카츄/이브이 쪽 의상이었고, 갈색시티 포켓몬애호가 클럽에서 받았던 피카츄세트/이브이세트가 주인공쪽 의상이었던 걸 감안하면, 사실상 처음 입수하게 된 의상 세트입니다. 선원 세트는 처음으로 파트너 포켓몬과 주인공 모두에게 적용되는 세트이기 때문입니다.\\n\\n\\u200b\\n\\n\\n\\n\\n\\n선원을 지나서도\\xa0길게 뻗은\\xa0부두를 지나서 갈색시티에 정박한 \\u200b거대 여객선 상트앙느호에 들어가게 됩니다. 이 부두에도 나름 사연이 있기는 한데, 나중에 이쪽을 지날 일이 있으면 언급하도록 하겠습니다.\\n\\n\\u200b\\n\\n\\n\\n\\n\\n안에 들어가서 통로쪽으로 가면 이벤트가 발생. 주인공보다 먼저 배에 들어온 라이벌이 \\u200b나름대로의 감상을 주인공에게 전해주는데, 뒤편에 회색시티에서 만났던 그린이 다가오게 됩니다.\\n\\n\\u200b\\n\\n\\n\\n\\n\\n\\u200b [...] 갈색시티 체육관 위에 있는 두 개의 민가 중 왼쪽에 있는 민가는 포켓몬애호가클럽입니다. 가운데 소파에 앉은 회장에게 말을 걸어 기나긴 얘기를 모두 듣고나면 파트너 포켓몬마다 다른 세트를 받을 수 있습니다.\\n\\n\\u200b\\n\\n\\n\\n\\n\\n\\u200b\\n\\n피카츄가 파트너 포켓몬인 레츠고! 피카츄에서는 주인공만 입을 수 있는 피카츄 세트를 받을 수 있습니다. 태초마을에서 라이벌과 첫번째 대결을 한 뒤 떠나기 전에 스포츠웨어를 받았었는데, 그 스포츠웨어가 주인공의 복장에 맞춘 피카츄 복장인 걸 감안하면 이번에는 반대로 주인공 쪽에서 피카츄에 맞춘 복장이라 할 수 있습니다.\\n\\n\\u200b\\n\\n\\n\\n\\n\\n\\u200b\\n\\n이브이가 파트너 포켓몬인 레츠고! 이브이에서는 주인공만 입을 수 있는 이브이 세트를 받을 수 있습니다. 이쪽도 주인공의 복장에 이브이가 맞췄던 스포츠웨어와 다르게 이브이에게 맞춘 주인공의 복장입니다.\\n\\n\\u200b\\n\\n\\n\\n\\n\\n\\u200b',\n",
       "  'score': 0.5874941},\n",
       " {'title': '태초마을 | 포켓몬 위키 - Fandom',\n",
       "  'url': 'https://pokemon.fandom.com/ko/wiki/%ED%83%9C%EC%B4%88%EB%A7%88%EC%9D%84',\n",
       "  'content': '아이템 | 게임 | 위치\\n | 상처약 | RGBPkFRLG | 주인공의 집의 PC\\n | 타운맵 | RGBPkFRLG | 스타팅 포켓몬을 받은 뒤그린의 집에 있는남나리에게서 받는다.\\n | 타운맵 | LPLE | 스타팅 포켓몬을 받은 뒤엄마에게서 받는다.\\n | 도감 | RGBPkFRLG | 오박사에게 물건을 전해준 뒤, 받는다.\\n | 도감 | LPLE | 파트너 포켓몬을 받은 뒤,오박사에게서 받는다.\\n×5 | 몬스터볼 | RGBPk | 22번도로에서라이벌을 이긴 뒤, 가방에 몬스터볼이 없고 새로 잡은 포켓몬이 없을 경우오박사에게서 받는다.\\n×5 | 몬스터볼 | FRLG | 오박사에게 물건을 전해준 뒤, 받는다.\\n×20 | 라즈열매 | LPLE | 오박사에게 물건을 전해준 뒤, 받는다.\\n | 키스톤 | LPLE | 배지를 7개 획득한 뒤,상록체육관에 갔다 오면그린에게서 받는다.\\n | 이상해꽃나이트 | LPLE | 배지를 7개 획득한 뒤,상록체육관에 갔다 오면그린에게서 받는다. [...] 관동지방\\n |  |  |  |  |  |  |  | \\n |  |  |  |  |  |  | [...] 파일:도트 7모델링 133.gif이브이♂Lv.6타입:노말특성:특성 없음도구:도구 없음몸통박치기노말물리울음소리노말변화---- | 파일:도트 7모델링 133.gif이브이♂Lv.6타입:노말특성:특성 없음도구:도구 없음 | 몸통박치기노말물리울음소리노말변화---- | 몸통박치기 | 노말 | 물리 | 울음소리 | 노말 | 변화 | -- | --\\n파일:도트 7모델링 133.gif이브이♂Lv.6타입:노말특성:특성 없음도구:도구 없음 | 몸통박치기노말물리울음소리노말변화---- | 몸통박치기 | 노말 | 물리 | 울음소리 | 노말 | 변화 | -- | --\\n몸통박치기\\n노말 | 물리\\n울음소리\\n노말 | 변화\\n--\\n\\n--\\n\\n | 라이벌진우오박사의 연구소레츠고! 피카츄 | 라이벌진우 | 오박사의 연구소레츠고! 피카츄\\n라이벌진우\\n오박사의 연구소레츠고! 피카츄\\n보상: 120원 | \\n라이벌진우\\n오박사의 연구소레츠고! 피카츄',\n",
       "  'score': 0.5373576},\n",
       " {'title': '[포켓몬 레드/적 공략] (1) - 태초마을~상록시티 (feat.피카츄를 잡아보자)',\n",
       "  'url': 'https://tkdcn137.tistory.com/24',\n",
       "  'content': '납치당하고나면 스타팅 포켓몬을 준다. \"파이리\". 불속성...불속성 중 ... 이제 태초마을을 손절할 때가 왔다.. 상록시티 ㄱㄱ. 상록시티에 도착',\n",
       "  'score': 0.51310796}]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = web_search_chain.invoke({\"character_name\": \"지우\", \"universe\": \"피카츄\", \"message\": \"처음 포켓몬을 받은 마을은 어디였지?\"})\n",
    "web_search_tool.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 답변 작성 Chain 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "rag_system_prompt = \"\"\"You are a character engaged in a roleplay with the user.\n",
    "Respond to the user's messages based on the pieces of retrieved context provided.\n",
    "If the context is not needed, you may answer without using it.\n",
    "If you're asked something you don't know, simply say you don't know.\n",
    "Pay close attention to the context of the conversation provided by the user, and respond in a way that stays true to the profile of the character you are roleplaying.\n",
    "Always follow up your response with an appropriate question to keep the conversation going.\"\"\"\n",
    "\n",
    "rag_user_prompt = \"\"\"Character Profile and User Name : {profile}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Conversations: {messages}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rag_system_prompt),\n",
    "        (\"user\", rag_user_prompt)\n",
    "    ]\n",
    ")\n",
    "\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "def EvalResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Response evaluation class.\n",
    "    The decision attribute can have a value of 'yes' or 'no' indicating the relevance of the response to the conversation.\n",
    "    \"\"\"\n",
    "    decision: str = Field(description=\"Response is relevant to message. This attribute can have a value of 'yes' or 'no'\")\n",
    "    \n",
    "    \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "response_llm_evaluator = llm.with_structured_output(EvalResponse)\n",
    "\n",
    "response_eval_system = \"\"\"You are a character engaged in a roleplay with the user.\n",
    "Your role is to evaluate whether a response is appropriate to the conversation based on the character's profile and context.\n",
    "Determine whether your response is appropriate to the conversation.\n",
    "If your response properly addresses the issue or question in the conversation, output 'yes'; otherwise, output 'no'.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "response_eval_user_prompt = \"\"\"Character Profile and User Name : {profile}\n",
    "Context: {context}\n",
    "\n",
    "Conversations: {messages}\n",
    "\n",
    "Your Response: {response}\n",
    "\n",
    "Decision:\"\"\"\n",
    "\n",
    "response_eval_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", response_eval_system),\n",
    "        (\"user\", response_eval_user_prompt)\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_eval_chain = response_eval_prompt | response_llm_evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAG의 개념과 기능에 대해 설명해 줄 수 있나요?'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a question rewriter that refines input queries to enhance their effectiveness for vector store retrieval or web searching by capturing their underlying semantic intent.\"\"\"\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"user\",\"Here is the original question:\\n{question}\\n\\nPlease rewrite it to improve clarity and optimize it for retrieval.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": \"RAG에 대해서 알려주세요\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. profiling_llm\n",
    "#2. web_search_tool\n",
    "#3. info_web_search_chain\n",
    "#4. vectorstore\n",
    "#5. retriever\n",
    "#6. retrieval_evaluator\n",
    "#7. web_search_chain\n",
    "#8. rag_chain\n",
    "#9. response_eval_chain\n",
    "#10. question_rewriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "def ConversationState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    documents: Annotated[list, add_messages]\n",
    "    web_query: Annotated[list, add_messages]\n",
    "    user_message: str\n",
    "    generation: str\n",
    "    retries:int\n",
    "    profile: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_messages(messages):\n",
    "    return [SystemMessage(content=profile_system_prompt)] + messages\n",
    "\n",
    "def profile_node(state):\n",
    "    print(\"--- Profiling ---\")\n",
    "    messages = get_profile_messages(state[\"messages\"])\n",
    "    response = profiling_llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "    \n",
    "#     if response.tool_calls: # Tool Call 발생한 경우\n",
    "#         profile = response.tool_calls[0][\"args\"]\n",
    "#         return {\"messages\": [response], \"profile\": profile}\n",
    "#     else:\n",
    "#         return {\"messages\": [response]}\n",
    "\n",
    "# state = profile_node({\"messages\": [HumanMessage(content=\"대화하고 싶어\")]})\n",
    "# print(state)\n",
    "\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "def route_message(state):\n",
    "    print(\"--- Route Message ---\")\n",
    "    messages = state[\"messages\"]\n",
    "    profile = state.get(\"profile\")\n",
    "    \n",
    "    \n",
    "    if profile: # Profile 수집 완료 상태, 대화 시작\n",
    "        return \"retriever\"\n",
    "    elif isinstance(messages[-1], AIMessage) and messages[-1].tool_calls: # Tool Call 발생했을 경우 Profile 수집 완료, \"profile_web_search\"로 라우팅\n",
    "        return \"profile_web_search\"\n",
    "    else: # 사용자에게 재질문하기 위해 Graph Escape\n",
    "        return END\n",
    "    \n",
    "    \n",
    "def profile_web_search(state):\n",
    "    print(\"--- Profile Web Search ---\")\n",
    "    messages = state[\"messages\"]\n",
    "    profile = messages.tool_calls[0][\"args\"]\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
